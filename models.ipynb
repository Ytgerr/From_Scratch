{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02ee9eb",
   "metadata": {},
   "source": [
    "### MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c12e0",
   "metadata": {},
   "source": [
    "### Linear model\n",
    "- Простые и **Интерпретируемые** \n",
    "- Модель называют линейной, если она является линейной по этим численным признакам.\n",
    "- Работает только с **численными** признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67634cfc",
   "metadata": {},
   "source": [
    "### Линейная регрессия и метод наименьших квадратов (МНК)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55adeee8",
   "metadata": {},
   "source": [
    "Пусть у нас задан датасет $(X, y)$, где \n",
    "\n",
    "$$\n",
    "y = (y_i)_{i=1}^N \\in \\mathbb{R}^N\n",
    "$$\n",
    "\n",
    "— вектор значений целевой переменной, а\n",
    "\n",
    "$$\n",
    "X = (x_i)_{i=1}^N \\in \\mathbb{R}^{N \\times D}, \\quad x_i \\in \\mathbb{R}^D\n",
    "$$\n",
    "\n",
    "— матрица \"объект-признак\", где i-я строка — это вектор признаков i-го объекта выборки.  \n",
    "\n",
    "Мы хотим моделировать зависимость $y_i$ от $x_i$ как линейную функцию со свободным членом:\n",
    "\n",
    "$$\n",
    "f_w(x_i) = \\langle w, x_i \\rangle + w_0\n",
    "$$\n",
    "\n",
    "где $w \\in \\mathbb{R}^D$ — вектор весов, а $w_0 \\in \\mathbb{R}$ — свободный член (bias).\n",
    "\n",
    "Используя Mean Squared Error, мы хотим оптимизировать Минимизируем по \\( w \\):\n",
    "\n",
    "$$\n",
    "\\min_{w} \\| y - X w \\|_2^2\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5adf569",
   "metadata": {},
   "source": [
    "### Аналитический метод МНК\n",
    "Аналитическое решение:\n",
    "\n",
    "$$\n",
    "w = (X^T X)^{-1} X^T y\n",
    "$$\n",
    "\n",
    "Вычислительная сложность:\n",
    "\n",
    "$$\n",
    "O(D^2 N + D^3)\n",
    "$$\n",
    "\n",
    "где \\(N\\) — размер выборки, \\(D\\) — число признаков.  \n",
    "- \\(ND^2\\) — сложность перемножения матриц \\(X^T X\\) и \\(X^T y\\),  \n",
    "- \\(D^3\\) — сложность обращения матрицы.  \n",
    "\n",
    "Рекомендации: не перемножайте \\((X^T X)^{-1}\\) и \\(X^T\\) напрямую; лучше сначала умножить \\(X^T y\\), а потом умножить на \\((X^T X)^{-1}\\).  \n",
    "\n",
    "Проблемы точного решения:  \n",
    "- Обращение больших матриц вычислительно дорого, особенно при миллионах объектов.  \n",
    "- Матрица \\(X^T X\\) может быть плохо обусловлена, что делает решение численно нестабильным: малые изменения \\(y\\) могут сильно менять \\(w\\).  \n",
    "\n",
    "Для ускорения и стабильности используют итерационные методы или продвинутые алгоритмы перемножения матриц.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d598003",
   "metadata": {},
   "source": [
    "### Численный метод МНК\n",
    "Градиентный спуск"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
